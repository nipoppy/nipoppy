"""Tests for the dataset status workflow."""

from pathlib import Path

import numpy as np
import pandas as pd
import pytest

from nipoppy.tabular.bagel import Bagel
from nipoppy.tabular.doughnut import Doughnut
from nipoppy.tabular.manifest import Manifest
from nipoppy.workflows.dataset_status import StatusWorkflow

# from .conftest import get_config


@pytest.fixture()
def dpath_root(tmp_path: Path) -> Path:
    return tmp_path


clipboard_emoji = "ðŸ“‹"
sad_cat_emoji = "ðŸ˜¿"
broom_emoji = "ðŸ§¹"
doughnut_emoji = "ðŸ©"
sparkles_emoji = "âœ¨"
rocket_emoji = "ðŸš€"
bagel_emoji = "ðŸ¥¯"
party_popper_emoji = "ðŸŽ‰"
confetti_emoji = "ðŸŽŠ"

# based on quantity
medium_throughput = 100
sushi_emoji = "ðŸ£"  # 100 subjects in BIDS
shaved_ice_emoji = "ðŸ§"  # 100 subjects processed

# other emojis
surprise_box_emoji = "ðŸŽ"
high_throughput = 1000
bento_box_emoji = "ðŸ±"  # 1000 subjects in BIDS
mate_emoji = "ðŸ§‰"  # 1000 subjects processed
night_owl_emoji = "ðŸ¦‰"
slow_sloth_emoji = "ðŸ¦¥"
quick_tiger_emoji = "ðŸ…"


def make_manifest(
    n_participants=10, session_ids=("BL", "M12"), randomize_counts=False
) -> Manifest:
    datatypes = ["anat", "dwi"]

    participant_ids = [str(i) for i in range(1, n_participants + 1)]

    # generate participants per session (potentially randomizing the number of participants)
    _df = pd.DataFrame(
        data={
            Manifest.col_session_id: session_ids[0],
            Manifest.col_participant_id: participant_ids,
            Manifest.col_visit_id: session_ids[0],
            Manifest.col_datatype: [datatypes for _ in range(n_participants)],
        }
    )

    _df_list = [_df]
    participant_counts = [len(participant_ids)]

    for session_id in session_ids[1:]:
        if randomize_counts:
            participant_count_for_session = np.random.randint(1, n_participants + 1)
        else:
            participant_count_for_session = n_participants

        _df = pd.DataFrame(
            data={
                Manifest.col_session_id: session_id,
                Manifest.col_participant_id: participant_ids[
                    :participant_count_for_session
                ],
                Manifest.col_visit_id: session_id,
                Manifest.col_datatype: [
                    datatypes for _ in range(participant_count_for_session)
                ],
            }
        )

        _df_list.append(_df)
        participant_counts.append(participant_count_for_session)

    _df = Manifest(pd.concat(_df_list))

    session_participant_counts_df = pd.DataFrame(
        data=zip(session_ids, participant_counts),
        columns=[Manifest.col_session_id, "participant_count"],
    )

    return _df, session_participant_counts_df


def make_doughnut(
    n_participants=10,
    session_ids=("BL", "M12"),
    n_success_percents=(80, 60, 40),
    randomize_counts=False,
) -> Doughnut:
    # reuse manifest generation
    doughnut, session_participant_counts_df = make_manifest(
        n_participants, session_ids, randomize_counts
    )

    participant_ids = doughnut["participant_id"].unique()

    # add pre_reorg, post_reorg, and bids status columns
    # always keep the first session as complete
    doughnut[
        [Doughnut.col_in_pre_reorg, Doughnut.col_in_post_reorg, Doughnut.col_in_bids]
    ] = False  # sets dtype to bool and avoids pandas warnings
    doughnut.loc[
        doughnut[Manifest.col_session_id] == session_ids[0], Doughnut.col_in_pre_reorg
    ] = True
    doughnut.loc[
        doughnut[Manifest.col_session_id] == session_ids[0], Doughnut.col_in_post_reorg
    ] = True
    doughnut.loc[
        doughnut[Manifest.col_session_id] == session_ids[0], Doughnut.col_in_bids
    ] = True

    participant_counts = [
        (len(participant_ids), len(participant_ids), len(participant_ids))
    ]
    # add the rest of the sessions
    for session_id in session_ids[1:]:
        n_session_participants = session_participant_counts_df[
            session_participant_counts_df[Manifest.col_session_id] == session_id
        ]["participant_count"].values[0]
        n_success_pre_reorg = int(n_session_participants * n_success_percents[0] / 100)
        n_success_post_reorg = int(n_session_participants * n_success_percents[1] / 100)
        n_success_bids = int(n_session_participants * n_success_percents[2] / 100)
        participant_counts.append(
            (n_success_pre_reorg, n_success_post_reorg, n_success_bids)
        )

        doughnut.loc[
            doughnut[Manifest.col_session_id] == session_id, Doughnut.col_in_pre_reorg
        ] = [True] * n_success_pre_reorg + [False] * (
            n_session_participants - n_success_pre_reorg
        )
        doughnut.loc[
            doughnut[Manifest.col_session_id] == session_id, Doughnut.col_in_post_reorg
        ] = [True] * n_success_post_reorg + [False] * (
            n_session_participants - n_success_post_reorg
        )
        doughnut.loc[
            doughnut[Manifest.col_session_id] == session_id, Doughnut.col_in_bids
        ] = [True] * n_success_bids + [False] * (
            n_session_participants - n_success_bids
        )

    session_participant_counts_df = pd.DataFrame(
        data=zip(session_ids, participant_counts),
        columns=["session_id", "participant_count"],
    )

    return Doughnut(doughnut), session_participant_counts_df


def make_bagel(
    n_participants=10,
    session_ids=("BL", "M12"),
    n_success_percent=50,
    pipeline_configs=(
        ("dcm2bids", "1.0.0", "prepare"),
        ("dcm2bids", "1.0.0", "convert"),
        ("fmriprep", "1.0.0", "default"),
    ),
    randomize_counts=False,
) -> Bagel:

    bagel, session_participant_counts_df = make_manifest(
        n_participants, session_ids, randomize_counts
    )

    participant_ids = bagel["participant_id"].unique()
    n_configs = len(pipeline_configs)
    # add pipeline columns
    _df_list = []
    for config in pipeline_configs:
        _df = bagel.copy()
        _df[
            [
                Bagel.col_pipeline_name,
                Bagel.col_pipeline_version,
                Bagel.col_pipeline_step,
            ]
        ] = config
        _df_list.append(_df)

    bagel = Bagel(pd.concat(_df_list))

    # add pipeline status columns
    # always keep the first session as complete for all pipelines
    bagel[[Bagel.col_status]] = "INCOMPLETE"
    bagel.loc[bagel[Manifest.col_session_id] == session_ids[0], Bagel.col_status] = (
        "SUCCESS"
    )

    # repeated participants for each pipeline config
    participant_counts = [n_configs * len(participant_ids)]

    # add the rest of the sessions
    for session_id in session_ids[1:]:
        n_session_participants = (
            n_configs
            * session_participant_counts_df[
                session_participant_counts_df[Manifest.col_session_id] == session_id
            ]["participant_count"].values[0]
        )
        n_success_pipeline = int(n_session_participants * n_success_percent / 100)
        participant_counts.append(n_success_pipeline)

        bagel.loc[bagel[Manifest.col_session_id] == session_id, Bagel.col_status] = [
            "SUCCESS"
        ] * n_success_pipeline + ["INCOMPLETE"] * (
            n_session_participants - n_success_pipeline
        )

    session_participant_counts_df = pd.DataFrame(
        data=zip(session_ids, participant_counts),
        columns=["session_id", "participant_count"],
    )

    return bagel, session_participant_counts_df


def make_status_df(
    n_participants,
    session_ids=("BL", "M12", "M24"),
    pipeline_configs=(
        ("dcm2bids", "1.0.0", "prepare"),
        ("dcm2bids", "1.0.0", "convert"),
        ("fmriprep", "1.0.0", "default"),
    ),
    emojis={
        "M12": {
            "init\nrewards": [clipboard_emoji],
            "curation\nrewards": [doughnut_emoji, broom_emoji],
            "processing\nrewards": [bagel_emoji, party_popper_emoji],
        },
        "M24": {
            "init\nrewards": [sad_cat_emoji],
            "curation\nrewards": [],
            "processing\nrewards": [],
        },
    },
) -> pd.DataFrame:

    doughnut_cols = ["in_pre_reorg", "in_post_reorg", "in_bids"]
    bagel_cols = [
        f"{config[0]}\n{config[1]}\n{config[2]}" for config in pipeline_configs
    ]
    status_df = pd.DataFrame(
        columns=["session_id", "in_manifest"] + doughnut_cols + bagel_cols
    )
    status_df["session_id"] = list(session_ids)

    # set BL session as complete
    status_df.loc[
        status_df["session_id"] == "BL", ["in_manifest"] + doughnut_cols + bagel_cols
    ] = n_participants

    # generate participants per session based on expected emoji rewards
    for session_id in session_ids[1:]:
        # initialize all doughnut and bagel status columns to 0 to avoid NaNs
        status_df.loc[status_df["session_id"] == session_id, "in_manifest"] = (
            n_participants
        )
        status_df.loc[
            status_df["session_id"] == session_id, doughnut_cols + bagel_cols
        ] = 0
        session_emojis = emojis[session_id]

        if sad_cat_emoji in session_emojis["init\nrewards"]:
            continue

        if clipboard_emoji in session_emojis["init\nrewards"]:
            if sparkles_emoji in session_emojis["curation\nrewards"]:
                status_df.loc[status_df["session_id"] == session_id, "in_pre_reorg"] = (
                    n_participants
                )
                status_df.loc[
                    status_df["session_id"] == session_id, "in_post_reorg"
                ] = n_participants
                status_df.loc[status_df["session_id"] == session_id, "in_bids"] = (
                    n_participants
                )

            elif doughnut_emoji in session_emojis["curation\nrewards"]:
                status_df.loc[status_df["session_id"] == session_id, "in_pre_reorg"] = (
                    n_participants
                )
                status_df.loc[
                    status_df["session_id"] == session_id, "in_post_reorg"
                ] = 1
                status_df.loc[status_df["session_id"] == session_id, "in_bids"] = 1

            elif broom_emoji in session_emojis["curation\nrewards"]:
                status_df.loc[status_df["session_id"] == session_id, "in_pre_reorg"] = 1
                status_df.loc[
                    status_df["session_id"] == session_id, "in_post_reorg"
                ] = 1
                status_df.loc[status_df["session_id"] == session_id, "in_bids"] = 0

            if bagel_emoji in session_emojis["processing\nrewards"]:
                status_df.loc[status_df["session_id"] == session_id, bagel_cols] = 1

            if confetti_emoji in session_emojis["processing\nrewards"]:
                status_df.loc[status_df["session_id"] == session_id, bagel_cols] = (
                    n_participants
                )

            elif party_popper_emoji in session_emojis["processing\nrewards"]:
                status_df.loc[status_df["session_id"] == session_id, bagel_cols[-1]] = (
                    n_participants
                )

            elif rocket_emoji in session_emojis["processing\nrewards"]:
                status_df.loc[status_df["session_id"] == session_id, bagel_cols[-1]] = 1

    return status_df


@pytest.mark.parametrize(
    "n_participants,session_ids,randomize_counts",
    [
        (10, ["BL", "M06", "M12", "M24"], False),
        (100, ["BL", "M06", "M12", "M24"], True),
    ],
)
def test_manifest(
    dpath_root: Path, n_participants: int, session_ids: list, randomize_counts: bool
):

    workflow = StatusWorkflow(dpath_root=dpath_root)
    workflow.manifest, session_participant_counts_df = make_manifest(
        n_participants=n_participants,
        session_ids=session_ids,
        randomize_counts=randomize_counts,
    )

    status_df = pd.DataFrame()
    status_df = workflow._check_manifest(status_df)

    status_df = pd.merge(
        status_df, session_participant_counts_df, on="session_id", how="left"
    )

    # check manifest status
    assert set(status_df[Manifest.col_session_id].unique()) == set(session_ids)
    assert status_df["in_manifest"].equals(status_df["participant_count"])


@pytest.mark.parametrize(
    "n_participants,session_ids,n_success_percents,randomize_counts",
    [
        (10, ["BL", "M06", "M12", "M24"], (80, 60, 40), False),
        (100, ["BL", "M06", "M12", "M24"], (100, 80, 0), True),
    ],
)
def test_doughnut(
    dpath_root: Path,
    n_participants: int,
    session_ids: list,
    n_success_percents: tuple,
    randomize_counts: bool,
):

    workflow = StatusWorkflow(dpath_root=dpath_root)
    workflow.doughnut, session_participant_counts_df = make_doughnut(
        n_participants=n_participants,
        session_ids=session_ids,
        n_success_percents=n_success_percents,
        randomize_counts=randomize_counts,
    )

    status_df = pd.DataFrame()
    status_df, _ = workflow._check_doughnut(status_df)

    status_df = pd.merge(
        status_df, session_participant_counts_df, on="session_id", how="left"
    )
    status_df["doughnut_counts"] = list(
        zip(
            status_df[Doughnut.col_in_pre_reorg],
            status_df[Doughnut.col_in_post_reorg],
            status_df[Doughnut.col_in_bids],
        )
    )

    # check manifest status
    assert set(status_df[Manifest.col_session_id].unique()) == set(session_ids)
    assert status_df["doughnut_counts"].equals(status_df["participant_count"])


@pytest.mark.parametrize(
    "n_participants,session_ids,n_success_percent,pipeline_configs,randomize_counts",
    [
        (
            10,
            ["BL", "M06", "M12", "M24"],
            50,
            (
                ("dcm2bids", "1.0.0", "prepare"),
                ("dcm2bids", "1.0.0", "convert"),
                ("fmriprep", "1.0.0", "default"),
            ),
            False,
        ),
        (
            100,
            ["BL", "M06", "M12", "M24"],
            100,
            (
                ("dcm2bids", "1.0.0", "prepare"),
                ("dcm2bids", "1.0.0", "convert"),
                ("fmriprep", "1.0.0", "default"),
            ),
            True,
        ),
    ],
)
def test_bagel(
    dpath_root: Path,
    n_participants: int,
    session_ids: list,
    n_success_percent: int,
    pipeline_configs: tuple,
    randomize_counts: bool,
):

    workflow = StatusWorkflow(dpath_root=dpath_root)
    workflow.bagel, session_participant_counts_df = make_bagel(
        n_participants=n_participants,
        session_ids=session_ids,
        n_success_percent=n_success_percent,
        pipeline_configs=pipeline_configs,
        randomize_counts=randomize_counts,
    )

    status_df = pd.DataFrame()
    status_df, bagel_cols = workflow._check_bagel(status_df)

    # pipeline_status_cols = [f"{config[0]}\n{config[1]}\n{config[2]}" for config in pipeline_configs]
    status_df = pd.merge(
        status_df, session_participant_counts_df, on="session_id", how="left"
    )

    # Sum up the bagel counts for all pipeline configs
    status_df["bagel_counts"] = 0
    for config in pipeline_configs:
        pipeline_status_col = f"{config[0]}\n{config[1]}\n{config[2]}"
        status_df["bagel_counts"] += status_df[pipeline_status_col]

    # check manifest status
    assert set(status_df[Manifest.col_session_id].unique()) == set(session_ids)
    assert status_df["bagel_counts"].equals(status_df["participant_count"])


@pytest.mark.parametrize(
    "n_participants,session_ids,pipeline_configs,emojis",
    [
        (
            10,
            ["BL", "M12", "M24"],
            (
                ("dcm2bids", "1.0.0", "prepare"),
                ("dcm2bids", "1.0.0", "convert"),
                ("fmriprep", "1.0.0", "default"),
            ),
            {
                "M12": {
                    "init\nrewards": [clipboard_emoji],
                    "curation\nrewards": [doughnut_emoji, broom_emoji],
                    "processing\nrewards": [bagel_emoji, party_popper_emoji],
                },
                "M24": {
                    "init\nrewards": [sad_cat_emoji],
                    "curation\nrewards": [],
                    "processing\nrewards": [],
                },
            },
        ),
        (
            150,
            ["BL", "M06", "M12", "M24"],
            (
                ("dcm2bids", "1.0.0", "prepare"),
                ("dcm2bids", "1.0.0", "convert"),
                ("fmriprep", "1.0.0", "default"),
            ),
            {
                "M06": {
                    "init\nrewards": [clipboard_emoji],
                    "curation\nrewards": [doughnut_emoji, broom_emoji],
                    "processing\nrewards": [bagel_emoji, party_popper_emoji],
                },
                "M12": {
                    "init\nrewards": [clipboard_emoji],
                    "curation\nrewards": [broom_emoji],
                    "processing\nrewards": [rocket_emoji],
                },
                "M24": {
                    "init\nrewards": [sad_cat_emoji],
                    "curation\nrewards": [],
                    "processing\nrewards": [],
                },
            },
        ),
    ],
)
def test_rewards(
    dpath_root: Path,
    n_participants: int,
    session_ids: list,
    pipeline_configs: tuple,
    emojis: dict,
):

    workflow = StatusWorkflow(dpath_root=dpath_root)

    status_df = make_status_df(n_participants, session_ids, pipeline_configs, emojis)

    doughnut_cols = ["in_pre_reorg", "in_post_reorg", "in_bids"]
    bagel_cols = [
        f"{config[0]}\n{config[1]}\n{config[2]}" for config in pipeline_configs
    ]

    # define the status columns and rewards columns
    status_col_dict = {
        "manifest": "in_manifest",
        "doughnut": doughnut_cols,
        "bids": "in_bids",  # also part of doughnut cols
        "bagel": bagel_cols,
    }
    reward_col_dict = {
        "manifest": "init\nrewards",
        "doughnut": "curation\nrewards",
        "bagel": "processing\nrewards",
    }

    status_df = workflow._add_manifest_rewards(
        status_df, status_col_dict, reward_col_dict["manifest"]
    )
    status_df = workflow._add_doughnut_rewards(
        status_df, status_col_dict, reward_col_dict["doughnut"]
    )
    status_df = workflow._add_bagel_rewards(
        status_df, status_col_dict, reward_col_dict["bagel"]
    )

    assert set(status_df[Manifest.col_session_id].unique()) == set(session_ids)

    # add BL emojis to the emojis dict
    emojis["BL"] = {
        "init\nrewards": [clipboard_emoji],
        "curation\nrewards": [doughnut_emoji, sparkles_emoji],
        "processing\nrewards": [bagel_emoji, confetti_emoji],
    }
    for session_id in session_ids:
        session_df = status_df[status_df["session_id"] == session_id]
        for reward_col in reward_col_dict.values():
            awarded_emojis = session_df[reward_col].values[0].split()
            assert set(awarded_emojis) == set(emojis[session_id][reward_col])
