# Run MRIQC on a BIDS dataset

In this tutorial, you will learn how to use the Nipoppy {term}`CLI` to run the [MRIQC](https://mriqc.readthedocs.io/en/23.1.0/) pipeline (version 23.1.0) on the [ds004101](https://openneuro.org/datasets/ds004101/versions/1.0.1) BIDS dataset available from OpenNeuro.

Concretely, we will:

1. **Initialize** a Nipoppy dataset from a BIDS dataset
2. **Install** and set up the MRIQC processing pipeline
2. **Run** MRIQC on a single participant and session
3. **Track** the output files to check if processing was successful

```{note}
If you have not installed Nipoppy yet, instructions are available [here](../../overview/installation).
```

```{attention}
This tutorial assumes that [Apptainer](https://apptainer.org) (or Singularity) is installed on your system. If that is not the case, then you will not be able to run MRIQC with Nipoppy.
```

## Step 0: Download the BIDS dataset

We will use the [**ds004101 dataset**](https://openneuro.org/datasets/ds004101/versions/1.0.1) from OpenNeuro, which includes structural and functional MRI data for 9 subjects (2 sessions). The dataset can be downloaded by following instructions [here](https://openneuro.org/datasets/ds004101/versions/1.0.1/download). If you do not have DataLad or Node.js installed, you can use the shell script method:

- Click on the "Download shell script" link at the bottom of [this page](https://openneuro.org/datasets/ds004101/versions/1.0.1/download). This should download a file called `ds004101-1.0.1.sh` to your computer.
- Move `ds004101-1.0.1.sh` to the directory you will use for this tutorial.
- Open a Terminal window and go to the directory where you put the script. Then run:
  ```console
  $ bash ds004101-1.0.1.sh
  ```
- Depending on your internet connection, the above command may take a few minutes. Once it is done, you should have a new directory `ds004101-1.0.1` containing the BIDS dataset. Run `tree ds004101-1.0.1` to see the dataset content.

## Step 1: Initialize the Nipoppy dataset

Run the following command to create a Nipoppy dataset and populate it with the BIDS data:

```console
$ nipoppy init --dataset nipoppy_study --bids-source ds004101-1.0.1
```

This command creates a folder named `nipoppy_study` with subdirectories for raw data, processed (derivatives) data, pipeline configuration files, logs, etc. The `tree` command can be used to show the directory structure.

```console
$ tree -L 1 nipoppy_study
```

```{code-block}
:caption: Output
nipoppy_study/
├── bids
├── code
├── containers
├── derivatives
├── global_config.json
├── logs
├── manifest.tsv
├── pipelines
├── scratch
├── sourcedata
└── tabular
```

Nipoppy automatically generated a manifest file from the BIDS dataset. This file is considered the ground truth for which participants and sessions are available for processing.

```{code-block}
:caption: Content of `nipoppy_study/manifest.tsv`
participant_id  visit_id    session_id  datatype
09114           1pre        1pre        ['anat', 'func']
09114           2post       2post       ['fmap', 'func']
09160           1pre        1pre        ['anat', 'func']
09160           2post       2post       ['fmap', 'func']
09260           1pre        1pre        ['anat', 'fmap', 'func']
09260           2post       2post       ['fmap', 'func']
09300           1pre        1pre        ['anat', 'fmap', 'func']
09300           2post       2post       ['fmap', 'func']
09380           1pre        1pre        ['anat', 'fmap', 'func']
09380           2post       2post       ['fmap', 'func']
09381           1pre        1pre        ['anat', 'fmap', 'func']
09381           2post       2post       ['fmap', 'func']
10134           1pre        1pre        ['anat', 'fmap', 'func']
10134           2post       2post       ['fmap', 'func']
10332           1pre        1pre        ['anat', 'fmap', 'func']
10332           2post       2post       ['fmap', 'func']
10570           1pre        1pre        ['anat', 'fmap', 'func']
10570           2post       2post       ['fmap', 'func']
```

The `nipoppy status` prints out a summary of the dataset, including the number of participants who are in BIDS or have completed a pipeline.

```console
$ nipoppy status --dataset nipoppy_study
```

For now, the dataset only has BIDS data:

```{code-block}
:caption: Table in `nipoppy status` output
     Participant counts by session at each Nipoppy checkpoint
            ╷             ╷              ╷               ╷
 session_id │ in_manifest │ in_pre_reorg │ in_post_reorg │ in_bids
════════════╪═════════════╪══════════════╪═══════════════╪═════════
    1pre    │      9      │      0       │       0       │    9
   2post    │      9      │      0       │       0       │    9
            ╵             ╵              ╵               ╵
```

## Step 2: Modify the global configuration file

The `nipoppy init` command created the configuration file at `nipoppy_study/global_config.json`. This file may need to be updated with information specific to your computing environment. Initially, it will look like this:

```{literalinclude} ../../../../nipoppy/data/examples/sample_global_config.json
---
linenos: True
language: json
emphasize-lines: 3,8
---
```

By default, this file does not contain any pipeline-specific information, since the dataset does not have any pipelines installed yet. Still, there are fields that may need to be modified depending on your setup:
- If you are on a system that still uses Singularity (which has been renamed to Apptainer), you need to change `CONTAINER_CONFIG` -> `COMMAND` to `"singularity"` instead of `"apptainer"`
- If your group uses a shared directory for storing container image files, you can replace `"[[NIPOPPY_DPATH_ROOT]]/containers"` by the full path to that shared directory.
    - Alternatively, you can create a symlink from {{dpath_containers}} to that directory (then this line in the configuration can be deleted).

## Step 3: Install the MRIQC pipeline into the dataset

The following command can be used to check which pipelines can be run with the dataset:
```console
$ nipoppy pipeline list --dataset nipoppy_study
```

The output says that there are no available pipelines to be run:
```
INFO     No available bidsification pipelines
INFO     No available processing pipelines
INFO     No available extraction pipelines
```

That is because newly initialized Nipoppy dataset does not contain any pipelines. Pipeline configuration files are available on the [Zenodo data repository](https://zenodo.org/search?q=metadata.subjects.subject%3A%22Nipoppy%22&l=list&p=1&s=10&sort=bestmatch). The [configuration files for MRIQC](https://zenodo.org/records/15427844) can be downloaded by running the following:
```console
$ nipoppy pipeline install --dataset nipoppy_study 15427844
```

```{tip}
You can use the `nipoppy pipeline search` command to get the Zenodo IDs of available pipelines.
```

When running `nipoppy pipeline install`, you will be asked if you would like to download the MRIQC container. Type `y` and press `Enter` to do so. The download/building process may take ~10 minutes. The container image is downloaded to `nipoppy_study/containers/mriqc_23.1.0.sif`.

The pipeline installation process will add a `TEMPLATEFLOW_HOME` pipeline variable to the `nipoppy_study/global_config.json` file:

```
INFO     Adding 1 variable(s) to the global config file:
INFO             TEMPLATEFLOW_HOME       Path to the directory where TemplateFlow will store templates (can be empty)
```

Open `nipoppy_study/global_config.json` and set `TEMPLATEFLOW_HOME` to a meaningful location.

```{code-block} json
:emphasize-lines: 6
    "PIPELINE_VARIABLES": {
        "BIDSIFICATION": {},
        "PROCESSING": {
            "mriqc": {
                "23.1.0": {
                    "TEMPLATEFLOW_HOME": null
                }
            }
        },
        "EXTRACTION": {}
    },
```

In general, we recommend using a shared directory within your research group for all Templateflow files, but you can also set it to something like `"[[NIPOPPY_DPATH_ROOT]]/templateflow"` (`[[NIPOPPY_DPATH_ROOT]]` will be resolved to the full path of the `nipoppy_study` directory at runtime).

## Step 4: Run MRIQC on a single participant and session

Use `nipoppy process` to run MRIQC on a single participant and session. This could take around 15 minutes to complete.

```console
$ nipoppy process \
    --dataset nipoppy_study \
    --pipeline mriqc \
    --pipeline-version 23.1.0 \
    --participant-id 09114 \
    --session-id 1pre
```

Pipeline outputs are written to `nipoppy_study/derivatives/mriqc/23.1.0/output`:

```{code-block}
:caption: MRIQC output files
nipoppy_study/derivatives/mriqc/23.1.0/output/
├── dataset_description.json
├── logs
├── sub-09114
│   ├── figures
│   │   ├── sub-09114_ses-1pre_desc-background_T1w.svg
│   │   └── sub-09114_ses-1pre_desc-zoomed_T1w.svg
│   └── ses-1pre
│       └── anat
│           └── sub-09114_ses-1pre_T1w.json
└── sub-09114_ses-1pre_T1w.html
```

Log files can be found in `nipoppy_study/logs/process/mriqc-23.1.0`.

## Step 5: Track the pipeline processing status

Run `nipoppy track-processing` to determine the MRIQC processing status for each subject and session:

```console
$ nipoppy track-processing \
    --dataset nipoppy_study \
    --pipeline mriqc \
    --pipeline-version 23.1.0
```

The command will create an {term}`processing status file` at `nipoppy_study/derivatives/processing_status.tsv`. This file should have a `SUCCESS` status (last column) for participant `09114` session `ses-1pre`, and `FAIL` statuses in every other row, like this:

```
participant_id  bids_participant_id     session_id  pipeline_name   pipeline_version    pipeline_step   bids_session_id     status
09114           sub-09114               1pre        mriqc           23.1.0              default         ses-1pre            SUCCESS
09114           sub-09114               2post       mriqc           23.1.0              default         ses-2post           FAIL
09160           sub-09160               1pre        mriqc           23.1.0              default         ses-1pre            FAIL
09160           sub-09160               2post       mriqc           23.1.0              default         ses-2post           FAIL
09260           sub-09260               1pre        mriqc           23.1.0              default         ses-1pre            FAIL
09260           sub-09260               2post       mriqc           23.1.0              default         ses-2post           FAIL
09300           sub-09300               1pre        mriqc           23.1.0              default         ses-1pre            FAIL
09300           sub-09300               2post       mriqc           23.1.0              default         ses-2post           FAIL
09380           sub-09380               1pre        mriqc           23.1.0              default         ses-1pre            FAIL
09380           sub-09380               2post       mriqc           23.1.0              default         ses-2post           FAIL
09381           sub-09381               1pre        mriqc           23.1.0              default         ses-1pre            FAIL
09381           sub-09381               2post       mriqc           23.1.0              default         ses-2post           FAIL
10134           sub-10134               1pre        mriqc           23.1.0              default         ses-1pre            FAIL
10134           sub-10134               2post       mriqc           23.1.0              default         ses-2post           FAIL
10332           sub-10332               1pre        mriqc           23.1.0              default         ses-1pre            FAIL
10332           sub-10332               2post       mriqc           23.1.0              default         ses-2post           FAIL
10570           sub-10570               1pre        mriqc           23.1.0              default         ses-1pre            FAIL
10570           sub-10570               2post       mriqc           23.1.0              default         ses-2post           FAIL
```

Running `nipoppy status --dataset nipoppy_study` again will show a new column for the MRIQC pipeline showing that one participant has completed processing for the first session:

```{code-block}
:caption: Table in `nipoppy status` output
          Participant counts by session at each Nipoppy checkpoint
            ╷             ╷              ╷               ╷         ╷
            │             │              │               │         │  mriqc
            │             │              │               │         │ 23.1.0
 session_id │ in_manifest │ in_pre_reorg │ in_post_reorg │ in_bids │ default
════════════╪═════════════╪══════════════╪═══════════════╪═════════╪═════════
    1pre    │      9      │      0       │       0       │    9    │    1
   2post    │      9      │      0       │       0       │    9    │    0
            ╵             ╵              ╵               ╵         ╵
```

The {term}`processing status file` can also be uploaded to the [Neurobagel digest dashboard](https://digest.neurobagel.org/), which will produce interactive visualizations of pipeline processing statuses.

Finally, this file can be used directly as input to the [Neurobagel CLI](https://neurobagel.org/user_guide/cli/) when generating participant-level metadata about processing pipeline results.

## Step 6 (optional): Run MRIQC on the rest of the dataset

Use `nipoppy process` without the participant and session flags to process the rest of the dataset (in a loop). This will skip the participant-session that has previously been run successfully.

```console
$ nipoppy process \
    --dataset nipoppy_study \
    --pipeline mriqc \
    --pipeline-version 23.1.0
```

Then, run the tracking command again to update the {term}`processing status file`:

```console
$ nipoppy track-processing \
    --dataset nipoppy_study \
    --pipeline mriqc \
    --pipeline-version 23.1.0
```

```{note}
For this dataset specifically, MRIQC will fail on all `ses-2post` sessions because they do not have anatomical data.
```

And that's it! You have successfully run MRIQC on a BIDS dataset using Nipoppy!
